{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenSERGE Inference\n",
    "\n",
    "Load a trained checkpoint and perform road graph extraction on test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from openserge.models.wrapper import OpenSERGE\n",
    "from openserge.data.dataset import CityScale\n",
    "from openserge.utils.training import load_checkpoint\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cpu' if torch.mps.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint path\n",
    "checkpoint_path = '/Users/gbahl/Downloads/fiery_wind.pt'\n",
    "\n",
    "# Data configuration\n",
    "data_root = '/Users/gbahl/Code/OpenSERGE/data/Sat2Graph/data/'\n",
    "img_size = 512\n",
    "\n",
    "# Inference parameters\n",
    "junction_thresh = 0.4  # Threshold for junction detection\n",
    "edge_thresh = 0.4      # Threshold for edge prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "config = checkpoint.get('config', {})\n",
    "\n",
    "print(\"Checkpoint info:\")\n",
    "print(f\"  Epoch: {checkpoint['epoch']}\")\n",
    "print(f\"  Backbone: {config.get('backbone', 'resnet50')}\")\n",
    "print(f\"  k: {config.get('k', 'None')}\")\n",
    "\n",
    "if 'val_losses' in checkpoint and checkpoint['val_losses']:\n",
    "    val_loss = checkpoint['val_losses']['total']\n",
    "    print(f\"  Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "\n",
    "normalize_mean = config.get('normalize_mean')\n",
    "normalize_std = config.get('normalize_std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = OpenSERGE(\n",
    "    backbone=config.get('backbone', 'resnet50'),\n",
    "    k=config.get('k'),\n",
    "    use_fpn=True,\n",
    "    use_pos_encoding=True,\n",
    ").to(device)\n",
    "\n",
    "# Load weights\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Count parameters\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"\\nModel loaded successfully!\")\n",
    "print(f\"Parameters: {num_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset\n",
    "test_dataset = CityScale(data_root, split='train', img_size=img_size, aug=False, normalize_mean=normalize_mean, normalize_std=normalize_std)\n",
    "\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Image size: {img_size}x{img_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a test sample\n",
    "sample_idx = 2  # Change this to try different samples\n",
    "\n",
    "sample = test_dataset[sample_idx]\n",
    "image = sample['image']  # [3, H, W]\n",
    "junction_map_gt = sample['junction_map']  # [1, h, w]\n",
    "offset_map_gt = sample['offset_map']  # [2, h, w]\n",
    "edges_gt = sample['edges']  # List of edge tuples\n",
    "meta = sample['meta']\n",
    "\n",
    "print(f\"Sample {sample_idx}:\")\n",
    "print(f\"  Region: {meta['region_id']}\")\n",
    "print(f\"  Image shape: {image.shape}\")\n",
    "print(f\"  Ground truth junctions: {(junction_map_gt > 0.5).sum().item()}\")\n",
    "print(f\"  Ground truth edges: {len(edges_gt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input\n",
    "image_batch = image.unsqueeze(0).to(device)  # [1, 3, H, W]\n",
    "\n",
    "# Run model\n",
    "with torch.no_grad():\n",
    "    output = model(image_batch, j_thr=junction_thresh, e_thr=edge_thresh)\n",
    "print( output['graphs'][0]['edges'].shape)\n",
    "\n",
    "# Extract predictions\n",
    "cnn_output = output['cnn']\n",
    "graph_output = output['graphs'][0]  # First (and only) batch item\n",
    "print(cnn_output.keys())\n",
    "print(graph_output.keys())\n",
    "# CNN outputs\n",
    "junction_logits = cnn_output['junction_logits'][0, 0].cpu()  # [h, w]\n",
    "junction_probs = torch.sigmoid(junction_logits)\n",
    "offset_pred = cnn_output['offset'][0].cpu()  # [2, h, w]\n",
    "\n",
    "# Graph outputs\n",
    "nodes = graph_output['nodes'].cpu().numpy()  # [N, 2] in pixel coordinates\n",
    "edges = graph_output['edges'].cpu().numpy()  # [E, 2] edge indices\n",
    "edge_probs = graph_output['edge_probs'].cpu().numpy()  # [E] edge probabilities\n",
    "\n",
    "print(f\"\\nPrediction results:\")\n",
    "print(f\"  Detected junctions: {len(nodes)}\")\n",
    "print(f\"  Junction probability range: [{junction_probs.min():.3f}, {junction_probs.max():.3f}]\")\n",
    "print(f\"  Predicted edges (after threshold): {len(edges)}\")\n",
    "if len(edge_probs) > 0:\n",
    "    print(f\"  Edge probability range: [{edge_probs.min():.3f}, {edge_probs.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare image for visualization\n",
    "img_vis = image.permute(1, 2, 0).cpu().numpy()  # [H, W, 3]\n",
    "img_vis = img_vis * normalize_std + normalize_mean\n",
    "img_vis = (img_vis * 255).astype(np.uint8)\n",
    "\n",
    "# Prepare ground truth visualization\n",
    "junction_gt = junction_map_gt[0].cpu().numpy()  # [h, w]\n",
    "h, w = junction_gt.shape\n",
    "\n",
    "# Resize junction maps to image size for visualization\n",
    "junction_gt_vis = cv2.resize(junction_gt, (img_size, img_size), interpolation=cv2.INTER_NEAREST)\n",
    "junction_pred_vis = cv2.resize(junction_probs.numpy(), (img_size, img_size), interpolation=cv2.INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Row 1: Ground Truth\n",
    "# Original image\n",
    "axes[0, 0].imshow(img_vis)\n",
    "axes[0, 0].set_title('Input Image', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# Ground truth junction map\n",
    "axes[0, 1].imshow(img_vis)\n",
    "axes[0, 1].imshow(junction_gt_vis, alpha=0.5, cmap='hot', vmin=0, vmax=1)\n",
    "axes[0, 1].set_title('Ground Truth Junctions', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# Ground truth graph WITH OFFSETS APPLIED\n",
    "axes[0, 2].imshow(img_vis)\n",
    "# Extract node positions from ground truth\n",
    "stride = img_size // h\n",
    "junction_positions = np.argwhere(junction_gt > 0.5)  # [N, 2] in (i, j) grid coords\n",
    "if len(junction_positions) > 0:\n",
    "    # Get offsets for junction positions\n",
    "    offset_gt = offset_map_gt.cpu().numpy()  # [2, h, w]\n",
    "    i_coords = junction_positions[:, 0]\n",
    "    j_coords = junction_positions[:, 1]\n",
    "    \n",
    "    # Extract offsets at junction locations\n",
    "    y_offsets = offset_gt[0, i_coords, j_coords]  # y offsets\n",
    "    x_offsets = offset_gt[1, i_coords, j_coords]  # x offsets\n",
    "    \n",
    "    # Convert to pixel coordinates with offsets applied\n",
    "    # Base position at cell center + offset (scaled to pixels)\n",
    "    x_positions = (j_coords + 0.5 + x_offsets) * stride\n",
    "    y_positions = (i_coords + 0.5 + y_offsets) * stride\n",
    "    nodes_gt = np.stack([x_positions, y_positions], axis=1)  # [N, 2]\n",
    "    \n",
    "    axes[0, 2].scatter(nodes_gt[:, 0], nodes_gt[:, 1], c='red', s=50, alpha=0.7, \n",
    "                       edgecolors='white', linewidths=1)\n",
    "    \n",
    "    # Draw edges using refined node positions\n",
    "    # Create mapping from (i,j) to refined position\n",
    "    coord_to_pos = {(i, j): (x, y) for (i, j), (x, y) in \n",
    "                    zip(junction_positions, nodes_gt)}\n",
    "    \n",
    "    for (i1, j1), (i2, j2) in edges_gt:\n",
    "        if (i1, j1) in coord_to_pos and (i2, j2) in coord_to_pos:\n",
    "            x1, y1 = coord_to_pos[(i1, j1)]\n",
    "            x2, y2 = coord_to_pos[(i2, j2)]\n",
    "            axes[0, 2].plot([x1, x2], [y1, y2], 'yellow', linewidth=2, alpha=0.6)\n",
    "\n",
    "axes[0, 2].set_title(f'Ground Truth Graph (with offsets) ({len(junction_positions)} nodes, {len(edges_gt)} edges)', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "# Row 2: Predictions\n",
    "# Junction probability heatmap\n",
    "axes[1, 0].imshow(img_vis)\n",
    "im = axes[1, 0].imshow(junction_pred_vis, alpha=0.6, cmap='hot', vmin=0, vmax=1)\n",
    "axes[1, 0].set_title('Predicted Junction Probability', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].axis('off')\n",
    "plt.colorbar(im, ax=axes[1, 0], fraction=0.046, pad=0.04)\n",
    "\n",
    "# Detected junctions (thresholded)\n",
    "axes[1, 1].imshow(img_vis)\n",
    "if len(nodes) > 0:\n",
    "    axes[1, 1].scatter(nodes[:, 0], nodes[:, 1], c='lime', s=50, alpha=0.8, \n",
    "                       edgecolors='white', linewidths=1, marker='o')\n",
    "axes[1, 1].set_title(f'Detected Junctions (threshold={junction_thresh})', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "# Predicted graph\n",
    "axes[1, 2].imshow(img_vis)\n",
    "if len(nodes) > 0:\n",
    "    # Draw edges\n",
    "    for edge_idx, (src, dst) in enumerate(edges):\n",
    "        x1, y1 = nodes[src]\n",
    "        x2, y2 = nodes[dst]\n",
    "        # Color by edge probability\n",
    "        prob = edge_probs[edge_idx]\n",
    "        color = plt.cm.viridis(prob)\n",
    "        axes[1, 2].plot([x1, x2], [y1, y2], color=color, linewidth=2, alpha=0.7)\n",
    "    \n",
    "    # Draw nodes on top\n",
    "    axes[1, 2].scatter(nodes[:, 0], nodes[:, 1], c='red', s=50, alpha=0.9,\n",
    "                       edgecolors='white', linewidths=1.5, marker='o', zorder=10)\n",
    "\n",
    "axes[1, 2].set_title(f'Predicted Graph ({len(nodes)} nodes, {len(edges)} edges)', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offset Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize offset predictions as quiver plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Ground truth offsets\n",
    "offset_gt = offset_map_gt.cpu().numpy()  # [2, h, w]\n",
    "mask_gt = (junction_gt > 0.5)\n",
    "\n",
    "# Downsample for visualization\n",
    "step = 2\n",
    "y_grid, x_grid = np.meshgrid(np.arange(0, h, step), np.arange(0, w, step), indexing='ij')\n",
    "y_grid = y_grid.astype(np.float64)\n",
    "x_grid = x_grid.astype(np.float64)\n",
    "y_grid += 0.5\n",
    "x_grid += 0.5\n",
    "\n",
    "# Ground truth\n",
    "axes[0].imshow(img_vis)\n",
    "offset_x_gt = offset_gt[1, ::step, ::step]  # x offsets\n",
    "offset_y_gt = offset_gt[0, ::step, ::step]  # y offsets\n",
    "mask_gt_down = mask_gt[::step, ::step]\n",
    "\n",
    "# Scale offsets to image coordinates\n",
    "scale = img_size / h\n",
    "axes[0].quiver(x_grid * scale, y_grid * scale, \n",
    "               offset_x_gt * scale, offset_y_gt * scale,\n",
    "               mask_gt_down.astype(float), \n",
    "               cmap='autumn', scale=1, scale_units='xy', angles='xy',\n",
    "               width=0.003, alpha=0.7)\n",
    "axes[0].set_title('Ground Truth Offsets', fontsize=14, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Predictions\n",
    "offset_pred_np = offset_pred.numpy()  # [2, h, w]\n",
    "mask_pred = (junction_probs.numpy() > 0.0)\n",
    "\n",
    "axes[1].imshow(img_vis)\n",
    "offset_x_pred = offset_pred_np[1, ::step, ::step]\n",
    "offset_y_pred = offset_pred_np[0, ::step, ::step]\n",
    "mask_pred_down = mask_pred[::step, ::step]\n",
    "\n",
    "axes[1].quiver(x_grid * scale, y_grid * scale,\n",
    "               offset_x_pred * scale, offset_y_pred * scale,\n",
    "               mask_pred_down.astype(float),\n",
    "               cmap='autumn', scale=1, scale_units='xy', angles='xy',\n",
    "               width=0.003, alpha=0.7)\n",
    "axes[1].set_title('Predicted Offsets', fontsize=14, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple comparison metrics\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"COMPARISON METRICS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Junction counts\n",
    "num_junctions_gt = (junction_gt > 0.5).sum()\n",
    "num_junctions_pred = len(nodes)\n",
    "print(f\"\\nJunctions:\")\n",
    "print(f\"  Ground Truth: {num_junctions_gt}\")\n",
    "print(f\"  Predicted:    {num_junctions_pred}\")\n",
    "print(f\"  Difference:   {num_junctions_pred - num_junctions_gt:+d}\")\n",
    "\n",
    "# Edge counts\n",
    "num_edges_gt = len(edges_gt)\n",
    "num_edges_pred = len(edges)\n",
    "print(f\"\\nEdges:\")\n",
    "print(f\"  Ground Truth: {num_edges_gt}\")\n",
    "print(f\"  Predicted:    {num_edges_pred}\")\n",
    "print(f\"  Difference:   {num_edges_pred - num_edges_gt:+d}\")\n",
    "\n",
    "# Pixel-level junction detection metrics\n",
    "junction_pred_binary = (junction_probs > junction_thresh).float()\n",
    "junction_gt_tensor = torch.from_numpy(junction_gt).float()\n",
    "\n",
    "tp = (junction_pred_binary * junction_gt_tensor).sum().item()\n",
    "fp = (junction_pred_binary * (1 - junction_gt_tensor)).sum().item()\n",
    "fn = ((1 - junction_pred_binary) * junction_gt_tensor).sum().item()\n",
    "tn = ((1 - junction_pred_binary) * (1 - junction_gt_tensor)).sum().item()\n",
    "\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(f\"\\nPixel-level Junction Metrics:\")\n",
    "print(f\"  Precision: {precision:.3f}\")\n",
    "print(f\"  Recall:    {recall:.3f}\")\n",
    "print(f\"  F1 Score:  {f1:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Different Samples\n",
    "\n",
    "Run the cells below to quickly test on different samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick inference function\n",
    "def infer_and_visualize(sample_idx, j_thresh=0.5):\n",
    "    \"\"\"Run inference and visualize results for a given sample.\"\"\"\n",
    "\n",
    "    # Load sample\n",
    "    sample = test_dataset[sample_idx]\n",
    "    image = sample['image']\n",
    "    junction_gt = sample['junction_map'][0].cpu().numpy()\n",
    "    offset_map_gt = sample['offset_map']  # [2, h, w]\n",
    "    edges_gt = sample['edges']\n",
    "    meta = sample['meta']\n",
    "\n",
    "    # Run inference\n",
    "    with torch.no_grad():\n",
    "        output = model(image.unsqueeze(0).to(device), j_thr=j_thresh)\n",
    "\n",
    "    # Extract results\n",
    "    nodes = output['graphs'][0]['nodes'].cpu().numpy()\n",
    "    edges = output['graphs'][0]['edges'].cpu().numpy()\n",
    "    edge_probs = output['graphs'][0]['edge_probs'].cpu().numpy()\n",
    "    junction_probs = torch.sigmoid(output['cnn']['junction_logits'][0, 0]).cpu().numpy()\n",
    "\n",
    "    # Visualize\n",
    "    img_vis = (image.permute(1, 2, 0).numpy() * 255).astype(np.uint8)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "    # Original\n",
    "    axes[0].imshow(img_vis)\n",
    "    axes[0].set_title(f'Sample {sample_idx}: {meta[\"region_id\"]}', fontsize=12, fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # Ground truth with offsets applied\n",
    "    axes[1].imshow(img_vis)\n",
    "    h, w = junction_gt.shape\n",
    "    stride = img_size // h\n",
    "    junction_positions = np.argwhere(junction_gt > 0.5)\n",
    "    if len(junction_positions) > 0:\n",
    "        # Get offsets for junction positions\n",
    "        offset_gt = offset_map_gt.cpu().numpy()  # [2, h, w]\n",
    "        i_coords = junction_positions[:, 0]\n",
    "        j_coords = junction_positions[:, 1]\n",
    "\n",
    "        # Extract offsets at junction locations\n",
    "        y_offsets = offset_gt[0, i_coords, j_coords]  # y offsets\n",
    "        x_offsets = offset_gt[1, i_coords, j_coords]  # x offsets\n",
    "\n",
    "        # Convert to pixel coordinates with offsets applied\n",
    "        x_positions = (j_coords + 0.5 + x_offsets) * stride\n",
    "        y_positions = (i_coords + 0.5 + y_offsets) * stride\n",
    "        nodes_gt = np.stack([x_positions, y_positions], axis=1)  # [N, 2]\n",
    "\n",
    "        axes[1].scatter(nodes_gt[:, 0], nodes_gt[:, 1], c='red', s=40, alpha=0.7)\n",
    "\n",
    "        # Draw edges using refined node positions\n",
    "        coord_to_pos = {(i, j): (x, y) for (i, j), (x, y) in\n",
    "                        zip(junction_positions, nodes_gt)}\n",
    "\n",
    "        for (i1, j1), (i2, j2) in edges_gt:\n",
    "            if (i1, j1) in coord_to_pos and (i2, j2) in coord_to_pos:\n",
    "                x1, y1 = coord_to_pos[(i1, j1)]\n",
    "                x2, y2 = coord_to_pos[(i2, j2)]\n",
    "                axes[1].plot([x1, x2], [y1, y2], 'yellow', linewidth=2, alpha=0.5)\n",
    "    axes[1].set_title(f'GT (with offsets): {len(junction_positions)} nodes, {len(edges_gt)} edges',\n",
    "                      fontsize=12, fontweight='bold')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # Prediction\n",
    "    axes[2].imshow(img_vis)\n",
    "    if len(nodes) > 0:\n",
    "        for src, dst in edges:\n",
    "            axes[2].plot([nodes[src, 0], nodes[dst, 0]],\n",
    "                        [nodes[src, 1], nodes[dst, 1]],\n",
    "                        'cyan', linewidth=2, alpha=0.6)\n",
    "        axes[2].scatter(nodes[:, 0], nodes[:, 1], c='lime', s=40, alpha=0.8,\n",
    "                       edgecolors='white', linewidths=1)\n",
    "    axes[2].set_title(f'Pred: {len(nodes)} nodes, {len(edges)} edges',\n",
    "                      fontsize=12, fontweight='bold')\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print stats\n",
    "    print(f\"Sample {sample_idx} - Junction threshold: {j_thresh}\")\n",
    "    print(f\"  GT: {len(junction_positions)} junctions, {len(edges_gt)} edges\")\n",
    "    print(f\"  Pred: {len(nodes)} junctions, {len(edges)} edges\")\n",
    "    print(f\"  Junction prob range: [{junction_probs.min():.3f}, {junction_probs.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try multiple samples\n",
    "for idx in range(min(5, len(test_dataset))):\n",
    "    infer_and_visualize(idx, j_thresh=junction_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different junction thresholds on the same sample\n",
    "sample_idx = 0\n",
    "thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "\n",
    "sample = test_dataset[sample_idx]\n",
    "image_batch = sample['image'].unsqueeze(0).to(device)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(thresholds), figsize=(4*len(thresholds), 4))\n",
    "\n",
    "for i, thresh in enumerate(thresholds):\n",
    "    with torch.no_grad():\n",
    "        output = model(image_batch, j_thr=thresh)\n",
    "    \n",
    "    nodes = output['graphs'][0]['nodes'].cpu().numpy()\n",
    "    edges = output['graphs'][0]['edges'].cpu().numpy()\n",
    "    \n",
    "    img_vis = (sample['image'].permute(1, 2, 0).numpy() * 255).astype(np.uint8)\n",
    "    axes[i].imshow(img_vis)\n",
    "    \n",
    "    if len(nodes) > 0:\n",
    "        for src, dst in edges:\n",
    "            axes[i].plot([nodes[src, 0], nodes[dst, 0]], \n",
    "                        [nodes[src, 1], nodes[dst, 1]], \n",
    "                        'cyan', linewidth=1.5, alpha=0.6)\n",
    "        axes[i].scatter(nodes[:, 0], nodes[:, 1], c='red', s=30, alpha=0.8)\n",
    "    \n",
    "    axes[i].set_title(f'Thresh={thresh}\\n{len(nodes)} nodes, {len(edges)} edges', \n",
    "                      fontsize=10)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to file\n",
    "import json\n",
    "\n",
    "def export_prediction(sample_idx, output_path):\n",
    "    \"\"\"Export prediction to JSON format.\"\"\"\n",
    "    \n",
    "    sample = test_dataset[sample_idx]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(sample['image'].unsqueeze(0).to(device), j_thr=junction_thresh)\n",
    "    \n",
    "    nodes = output['graphs'][0]['nodes'].cpu().numpy()\n",
    "    edges = output['graphs'][0]['edges'].cpu().numpy()\n",
    "    edge_probs = output['graphs'][0]['edge_probs'].cpu().numpy()\n",
    "    \n",
    "    result = {\n",
    "        'sample_idx': sample_idx,\n",
    "        'region_id': sample['meta']['region_id'],\n",
    "        'nodes': nodes.tolist(),\n",
    "        'edges': edges.tolist(),\n",
    "        'edge_probabilities': edge_probs.tolist(),\n",
    "        'num_nodes': len(nodes),\n",
    "        'num_edges': len(edges),\n",
    "        'junction_threshold': junction_thresh\n",
    "    }\n",
    "    \n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(result, f, indent=2)\n",
    "    \n",
    "    print(f\"Prediction saved to {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "# export_prediction(0, 'prediction_sample0.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openserge312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
